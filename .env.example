# .env template (DO NOT COMMIT)
# Copy this to .env and fill with your values

# ========== API/Inference Model Configuration ==========
# NOTE: These settings are for the API server (inference), NOT training.
# Training model is configured in config.yaml

# Base model from HuggingFace for API inference (default: google/flan-t5-base)
MODEL_ID=google/flan-t5-base

# (Optional) Path to LoRA adapter weights for inference
# Can be local path: /path/to/adapter
# Or S3 path: s3://your-bucket/path/to/adapter
# PEFT_WEIGHTS_PATH=/path/to/adapter

# (Optional) API key for request authentication
# API_KEY=your-secret-api-key

# AWS Credentials (required if using S3 paths for PEFT_WEIGHTS_PATH)
# AWS_ACCESS_KEY_ID=your_access_key_id
# AWS_SECRET_ACCESS_KEY=your_secret_access_key

# ========== SageMaker Configuration ==========
# IAM role for SageMaker execution (required for local development)
SAGEMAKER_ROLE_ARN=arn:aws:iam::YOUR_ACCOUNT_ID:role/SageMakerExecutionRole
